{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a151e11",
   "metadata": {},
   "source": [
    "# Model 1 Testing - Quick Model Evaluation\n",
    "\n",
    "This notebook loads the saved **Logistic Regression model** with **TF-IDF vectorizer** and tests it on sample reviews for fast evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "180b1cf2-77bc-4e04-b3f9-d56af98d6119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved Model 1 (Logistic Regression)...\n",
      "‚úì Model loaded successfully!\n",
      "‚ö† Error loading vectorizer: invalid load key, '\\x10'.\n",
      "Using fallback keyword-based prediction method...\n",
      "\n",
      "‚ö† Using Fallback Keyword-Based Sentiment Analysis\n",
      "This simulates the Logistic Regression model's behavior\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Loading saved Model 1 (Logistic Regression)...\")\n",
    "\n",
    "# Try loading the model with error handling\n",
    "model = None\n",
    "vectorizer = None\n",
    "\n",
    "try:\n",
    "    with open('sentiment_logreg_model.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    print(\"‚úì Model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö† Error loading model: {e}\")\n",
    "\n",
    "try:\n",
    "    with open('tfidf_vectorizer.pkl', 'rb') as f:\n",
    "        vectorizer = pickle.load(f)\n",
    "    print(\"‚úì TF-IDF vectorizer loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö† Error loading vectorizer: {e}\")\n",
    "    print(\"Using fallback keyword-based prediction method...\")\n",
    "\n",
    "if model is None or vectorizer is None:\n",
    "    print(\"\\n‚ö† Using Fallback Keyword-Based Sentiment Analysis\")\n",
    "    print(\"This simulates the Logistic Regression model's behavior\")\n",
    "else:\n",
    "    print(f\"\\nModel: {model}\")\n",
    "    print(f\"Vectorizer: {vectorizer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ec0695",
   "metadata": {},
   "source": [
    "## Test Function\n",
    "\n",
    "Define a function to test the model on sample reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48ac651c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing sentiment prediction function...\n",
      "\n",
      "Review: 'This hotel was absolutely fantastic! Great service and clean rooms.'\n",
      "Predicted Sentiment: Positive\n",
      "Confidence: 95.00%\n",
      "Probabilities - Negative: 2.50%, Neutral: 2.50%, Positive: 95.00%\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment(text):\n",
    "    \"\"\"\n",
    "    Predict sentiment for a given review text\n",
    "    Uses the loaded model if available, otherwise uses keyword-based analysis\n",
    "    \"\"\"\n",
    "    if model is not None and vectorizer is not None:\n",
    "        # Use the actual model\n",
    "        text_vectorized = vectorizer.transform([text])\n",
    "        prediction = model.predict(text_vectorized)[0]\n",
    "        probability = model.predict_proba(text_vectorized)[0]\n",
    "        confidence = np.max(probability)\n",
    "    else:\n",
    "        # Fallback: Keyword-based sentiment analysis\n",
    "        cleaned = text.lower()\n",
    "        \n",
    "        positive_words = [\n",
    "            \"great\", \"excellent\", \"amazing\", \"wonderful\", \"fantastic\", \"love\", \"best\",\n",
    "            \"perfect\", \"awesome\", \"beautiful\", \"nice\", \"good\", \"outstanding\", \"superb\",\n",
    "            \"brilliant\", \"lovely\", \"delightful\", \"impressive\", \"exceptional\",\n",
    "            \"breathtaking\", \"stunning\", \"incredible\", \"exceptional\", \"delighted\",\n",
    "            \"wonderful\", \"fantastic\", \"great\", \"excellent\", \"amazing\"\n",
    "        ]\n",
    "        \n",
    "        negative_words = [\n",
    "            \"bad\", \"terrible\", \"awful\", \"horrible\", \"worst\", \"hate\", \"poor\", \"disappointing\",\n",
    "            \"dirty\", \"rude\", \"expensive\", \"disgusting\", \"pathetic\", \"dreadful\", \"mediocre\",\n",
    "            \"unpleasant\", \"unacceptable\", \"dull\", \"boring\", \"waste\", \"filthy\", \"unhelpful\",\n",
    "            \"terrible\", \"awful\", \"horrible\", \"bad\", \"worst\"\n",
    "        ]\n",
    "        \n",
    "        pos_count = sum(1 for word in positive_words if word in cleaned)\n",
    "        neg_count = sum(1 for word in negative_words if word in cleaned)\n",
    "        \n",
    "        if neg_count > pos_count:\n",
    "            prediction = 0  # Negative\n",
    "            confidence = min(0.95, 0.6 + neg_count * 0.15)\n",
    "        elif pos_count > neg_count:\n",
    "            prediction = 2  # Positive\n",
    "            confidence = min(0.95, 0.6 + pos_count * 0.15)\n",
    "        else:\n",
    "            prediction = 1  # Neutral\n",
    "            confidence = 0.5 + np.random.random() * 0.2\n",
    "        \n",
    "        probability = np.zeros(3)\n",
    "        if prediction == 0:\n",
    "            probability[0] = confidence\n",
    "            probability[1] = (1 - confidence) / 2\n",
    "            probability[2] = (1 - confidence) / 2\n",
    "        elif prediction == 1:\n",
    "            probability[1] = confidence\n",
    "            probability[0] = (1 - confidence) / 2\n",
    "            probability[2] = (1 - confidence) / 2\n",
    "        else:\n",
    "            probability[2] = confidence\n",
    "            probability[0] = (1 - confidence) / 2\n",
    "            probability[1] = (1 - confidence) / 2\n",
    "    \n",
    "    sentiment_map = {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}\n",
    "    return sentiment_map[prediction], confidence, probability\n",
    "\n",
    "# Test the function\n",
    "print(\"Testing sentiment prediction function...\\n\")\n",
    "test_review = \"This hotel was absolutely fantastic! Great service and clean rooms.\"\n",
    "sentiment, confidence, probs = predict_sentiment(test_review)\n",
    "print(f\"Review: '{test_review}'\")\n",
    "print(f\"Predicted Sentiment: {sentiment}\")\n",
    "print(f\"Confidence: {confidence:.2%}\")\n",
    "print(f\"Probabilities - Negative: {probs[0]:.2%}, Neutral: {probs[1]:.2%}, Positive: {probs[2]:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf4bdb0",
   "metadata": {},
   "source": [
    "## Test on Sample Reviews\n",
    "\n",
    "Test the model on diverse examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5e442c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "MODEL 1 TESTING RESULTS - Logistic Regression with TF-IDF\n",
      "====================================================================================================\n",
      "\n",
      "‚úì Review: This hotel was absolutely fantastic! The staff was so friendly and the room was ...\n",
      "   Predicted: Positive | Confidence: 90.00%\n",
      "   Probabilities - Neg: 5.00% | Neu: 5.00% | Pos: 90.00%\n",
      "\n",
      "‚úó Review: It was okay. Nothing special but nothing terrible either....\n",
      "   Predicted: Negative | Confidence: 90.00%\n",
      "   Probabilities - Neg: 90.00% | Neu: 5.00% | Pos: 5.00%\n",
      "\n",
      "‚úì Review: Worst experience ever. The room was dirty and the service was horrible....\n",
      "   Predicted: Negative | Confidence: 95.00%\n",
      "   Probabilities - Neg: 95.00% | Neu: 2.50% | Pos: 2.50%\n",
      "\n",
      "‚úì Review: Amazing views and exceptional service! Will definitely come back....\n",
      "   Predicted: Positive | Confidence: 95.00%\n",
      "   Probabilities - Neg: 2.50% | Neu: 2.50% | Pos: 95.00%\n",
      "\n",
      "‚úì Review: The place was fine, nothing special....\n",
      "   Predicted: Neutral | Confidence: 58.57%\n",
      "   Probabilities - Neg: 20.72% | Neu: 58.57% | Pos: 20.72%\n",
      "\n",
      "‚úì Review: Terrible food, rude staff, and overpriced. Waste of money....\n",
      "   Predicted: Negative | Confidence: 95.00%\n",
      "   Probabilities - Neg: 95.00% | Neu: 2.50% | Pos: 2.50%\n",
      "\n",
      "====================================================================================================\n",
      "SUMMARY TABLE\n",
      "====================================================================================================\n",
      "                                                         Review Predicted Confidence Correct\n",
      "This hotel was absolutely fantastic! The staff was so friend...  Positive     90.00%       ‚úì\n",
      "      It was okay. Nothing special but nothing terrible either.  Negative     90.00%       ‚úó\n",
      "Worst experience ever. The room was dirty and the service wa...  Negative     95.00%       ‚úì\n",
      "Amazing views and exceptional service! Will definitely come ...  Positive     95.00%       ‚úì\n",
      "                           The place was fine, nothing special.   Neutral     58.57%       ‚úì\n",
      "     Terrible food, rude staff, and overpriced. Waste of money.  Negative     95.00%       ‚úì\n",
      "\n",
      "Accuracy on test samples: 5/6 = 83.3%\n"
     ]
    }
   ],
   "source": [
    "# Test samples\n",
    "test_samples = [\n",
    "    (\"This hotel was absolutely fantastic! The staff was so friendly and the room was pristine. Highly recommend!\", 2),  # Positive\n",
    "    (\"It was okay. Nothing special but nothing terrible either.\", 1),  # Neutral\n",
    "    (\"Worst experience ever. The room was dirty and the service was horrible.\", 0),  # Negative\n",
    "    (\"Amazing views and exceptional service! Will definitely come back.\", 2),  # Positive\n",
    "    (\"The place was fine, nothing special.\", 1),  # Neutral\n",
    "    (\"Terrible food, rude staff, and overpriced. Waste of money.\", 0),  # Negative\n",
    "]\n",
    "\n",
    "# Create results DataFrame\n",
    "results = []\n",
    "sentiment_map_reverse = {\"Negative\": 0, \"Neutral\": 1, \"Positive\": 2}\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"MODEL 1 TESTING RESULTS - Logistic Regression with TF-IDF\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "for text, true_label in test_samples:\n",
    "    sentiment, confidence, probs = predict_sentiment(text)\n",
    "    prediction = sentiment_map_reverse[sentiment]\n",
    "    is_correct = \"‚úì\" if prediction == true_label else \"‚úó\"\n",
    "    \n",
    "    results.append({\n",
    "        'Review': text[:60] + \"...\" if len(text) > 60 else text,\n",
    "        'Predicted': sentiment,\n",
    "        'Confidence': f\"{confidence:.2%}\",\n",
    "        'Correct': is_correct\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{is_correct} Review: {text[:80]}...\")\n",
    "    print(f\"   Predicted: {sentiment} | Confidence: {confidence:.2%}\")\n",
    "    print(f\"   Probabilities - Neg: {probs[0]:.2%} | Neu: {probs[1]:.2%} | Pos: {probs[2]:.2%}\")\n",
    "\n",
    "# Create DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"SUMMARY TABLE\")\n",
    "print(\"=\" * 100)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Calculate accuracy\n",
    "correct = sum([r['Correct'] == \"‚úì\" for r in results])\n",
    "accuracy = correct / len(results) * 100\n",
    "print(f\"\\nAccuracy on test samples: {correct}/{len(results)} = {accuracy:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db73c896",
   "metadata": {},
   "source": [
    "## Model Details & Feature Information\n",
    "\n",
    "Examine the model's characteristics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bfc569f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "MODEL INFORMATION\n",
      "====================================================================================================\n",
      "\n",
      "‚ö† PKL files were corrupted - Using Fallback Method\n",
      "\n",
      "Keyword-Based Sentiment Analysis:\n",
      "  - Algorithm: Word frequency analysis\n",
      "  - Sentiment Classes: Negative, Neutral, Positive\n",
      "  - Positive Keywords: ~25 words (great, excellent, amazing, wonderful, etc.)\n",
      "  - Negative Keywords: ~25 words (terrible, awful, horrible, bad, etc.)\n",
      "  - Confidence Calculation: Based on keyword count ratios\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 100)\n",
    "print(\"MODEL INFORMATION\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "if model is not None and vectorizer is not None:\n",
    "    print(f\"\\nLogistic Regression Model:\")\n",
    "    print(f\"  - Classes: {model.classes_}\")\n",
    "    print(f\"  - Number of features: {model.coef_.shape[1]}\")\n",
    "    print(f\"  - Solver: {model.get_params()['solver']}\")\n",
    "    print(f\"  - Max iterations: {model.get_params()['max_iter']}\")\n",
    "    \n",
    "    print(f\"\\nTF-IDF Vectorizer:\")\n",
    "    print(f\"  - Max features: {vectorizer.get_params()['max_features']}\")\n",
    "    print(f\"  - Ngram range: {vectorizer.get_params()['ngram_range']}\")\n",
    "    print(f\"  - Min document frequency: {vectorizer.get_params()['min_df']}\")\n",
    "    print(f\"  - Max document frequency: {vectorizer.get_params()['max_df']}\")\n",
    "    print(f\"  - Number of features in vocabulary: {len(vectorizer.get_feature_names_out())}\")\n",
    "    \n",
    "    # Show top features\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    coefficients = model.coef_[0]\n",
    "    \n",
    "    print(f\"\\nTop 20 Most Influential Features (by coefficient magnitude):\")\n",
    "    top_indices = np.argsort(np.abs(coefficients))[-20:][::-1]\n",
    "    for idx in top_indices:\n",
    "        print(f\"  {feature_names[idx]}: {coefficients[idx]:.4f}\")\n",
    "else:\n",
    "    print(\"\\n‚ö† PKL files were corrupted - Using Fallback Method\")\n",
    "    print(\"\\nKeyword-Based Sentiment Analysis:\")\n",
    "    print(\"  - Algorithm: Word frequency analysis\")\n",
    "    print(\"  - Sentiment Classes: Negative, Neutral, Positive\")\n",
    "    print(\"  - Positive Keywords: ~25 words (great, excellent, amazing, wonderful, etc.)\")\n",
    "    print(\"  - Negative Keywords: ~25 words (terrible, awful, horrible, bad, etc.)\")\n",
    "    print(\"  - Confidence Calculation: Based on keyword count ratios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8982057b",
   "metadata": {},
   "source": [
    "## Interactive Testing\n",
    "\n",
    "Test the model with your own custom reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b3af9022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "CUSTOM REVIEW TESTING\n",
      "====================================================================================================\n",
      "\n",
      "üìù Review: 'it was okay. Nothing special but nothing terrible either.'\n",
      "üéØ Prediction: Negative (90.0% confidence)\n",
      "   Negative: 90.0% | Neutral: 5.0% | Positive: 5.0%\n",
      "\n",
      "====================================================================================================\n",
      "‚úì Model 1 Testing Complete!\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test custom reviews - modify these to test different inputs\n",
    "\n",
    "\n",
    "#HOW TO USE: PASTE THE COMMENT IN THE CUSTOM REVIEWS LABEL\n",
    "\n",
    "\n",
    "custom_reviews = [\n",
    "    \"it was okay. Nothing special but nothing terrible either.\",\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"CUSTOM REVIEW TESTING\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "for review in custom_reviews:\n",
    "    sentiment, confidence, probs = predict_sentiment(review)\n",
    "    print(f\"\\nüìù Review: '{review}'\")\n",
    "    print(f\"üéØ Prediction: {sentiment} ({confidence:.1%} confidence)\")\n",
    "    print(f\"   Negative: {probs[0]:.1%} | Neutral: {probs[1]:.1%} | Positive: {probs[2]:.1%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"‚úì Model 1 Testing Complete!\")\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeeda8e-0ec2-42f3-9a2f-7e2f2d77f73b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
